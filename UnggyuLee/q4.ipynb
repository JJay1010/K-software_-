{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJay1010/K-software_-/blob/main/UnggyuLee/q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7wvRhulCH_P"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "from PIL import Image\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "#데이터 읽기import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zv1XixwCH_S"
      },
      "outputs": [],
      "source": [
        "\n",
        "#rootDir = 'C:/Users/lee/Desktop/swbootcamp/p4/유형별 두피 이미지/Training/'\n",
        "rootDir = 'E:/q4/유형별 두피 이미지/Training/'\n",
        "\n",
        "labelDirs = glob.glob(rootDir+'**/*.json',recursive=True)\n",
        "#imgDirs = glob.glob(rootDir+'**/*.jpg',recursive=True)\n",
        "\n",
        "imgs =[]\n",
        "labels = []\n",
        "width = 150\n",
        "height =150\n",
        "def decodeStatus(encodedStatus):\n",
        "    s0=re.compile('000000')\n",
        "    s1=re.compile('[123]00000')\n",
        "    s2=re.compile('0[123]0000')\n",
        "    s3=re.compile('[0123]0[123]000')\n",
        "    s4=re.compile('[0123][123][123]000')\n",
        "    s5=re.compile('[0123][0123]0[123][0123]0')\n",
        "    s6=re.compile('[0123][0123]00[123]0')\n",
        "    s7=re.compile('00000[123]')\n",
        "    if(s0.match(encodedStatus)):\n",
        "        return 0\n",
        "    elif(s1.match(encodedStatus)):\n",
        "        return 1\n",
        "    elif(s2.match(encodedStatus)):\n",
        "        return 2\n",
        "    elif(s3.match(encodedStatus)):\n",
        "        return 3\n",
        "    elif(s4.match(encodedStatus)):\n",
        "        return 4\n",
        "    elif(s5.match(encodedStatus)):\n",
        "        return 5\n",
        "    elif(s6.match(encodedStatus)):\n",
        "        return 6\n",
        "    elif(s7.match(encodedStatus)):\n",
        "        return 7\n",
        "    else:\n",
        "        #print(encodedStatus)\n",
        "        #print(\"abnormal pattern\")\n",
        "        return -1\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVx1WVwZCH_T"
      },
      "source": [
        "라벨링 방식\n",
        "        val1    val2       val3     val4        val5    val6  \n",
        "순서 : 미세각질,피지과다,모낭사이홍반,모낭홍반/농포,비듬,탈모  \n",
        "(01) <-상관없음\n",
        "\n",
        "양호 : 000000                                   ->regex(000000)  \n",
        "건성 : 100000                                   ->regex(100000)  \n",
        "지성 : 010000                                   ->regex(010000)  \n",
        "민감성 : (01)01000                              ->regex([01]01000)  \n",
        "지루성 : (01)11000                              ->regex([01]11000)  \n",
        "염증성 : (01)(01)01(01)0                        ->regex([01][01]01[01]0)   \n",
        "비듬성 : (01)(01)0010                           ->regex([01][01]0010)  \n",
        "탈모성 : 000001                                 ->regex(000001)\n",
        "\n",
        "상태값 매핑 : 양호0 건성1 지성2 민감성3 지루성4 염증성5 비듬성6 탈모성7 그외-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnEIRBbLCH_U"
      },
      "source": [
        "내일할일\n",
        "json에서 value 1~ value6 값을 읽어서 어떤 상태인지 판단 후 전처리\n",
        "예) 이미지 1, 양호 와 같은 식으로 이미지와 라벨 매칭\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6nWX2ZgCH_U"
      },
      "source": [
        "2일차\n",
        "문제 : 너무 많은 데이터를 메모리에 올릴 수가 없다.  \n",
        "generator을 쓰면 가능\n",
        "\n",
        "generator 써도 노트북으로는 너무 많은 시간 소모\n",
        "데이터셋을 줄일 방법을 생각해본다.  \n",
        "큰 batch 사이즈와 gpu사용으로 해결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALB3j9ZUCH_U",
        "outputId": "bf5a5ddc-7bce-46f1-e38f-ec7688518bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 34, 34, 64)        36928     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 73984)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4735040   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,791,945\n",
            "Trainable params: 4,791,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "start\n",
            "Epoch 1/3\n",
            "241/241 [==============================] - 1203s 5s/step - loss: 1.4111\n",
            "Epoch 2/3\n",
            "241/241 [==============================] - 1221s 5s/step - loss: 1.2262\n",
            "Epoch 3/3\n",
            "241/241 [==============================] - 1091s 5s/step - loss: 1.2071\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#모델 빌드\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64,activation='relu'),\n",
        "    tf.keras.layers.Dense(9,activation='softmax')\n",
        "])\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "model.summary()\n",
        "length = 0\n",
        "def gen():\n",
        "    for lDir in labelDirs:\n",
        "        with open(lDir,'r',encoding='UTF8') as file:\n",
        "                data = json.load(file)\n",
        "                #print(data)\n",
        "                #print(data['value_1']+data['value_2']+data['value_3']+data['value_4']+data['value_5']+data['value_6'])\n",
        "                encodedStatus = data['value_1']+data['value_2']+data['value_3']+data['value_4']+data['value_5']+data['value_6']\n",
        "                \n",
        "        \n",
        "                imgDir = (lDir.replace('라벨','원천')).replace('json','jpg')\n",
        "                #print(imgDir)\n",
        "                imgData = np.array(Image.open(imgDir).resize((width,height)).convert('RGB'))\n",
        "                imgData = imgData/255 \n",
        "               \n",
        "            \n",
        "\n",
        "                label = decodeStatus(encodedStatus)\n",
        "                label=np.array(label)\n",
        "                label=keras.utils.to_categorical(label,9)\n",
        "                label=label.astype(np.int8)\n",
        "               \n",
        "\n",
        "                \n",
        "                yield(imgData,label)\n",
        "              \n",
        "d = tf.data.Dataset.from_generator(gen,(tf.int16,9),((width,height,3),(9)))\n",
        "d = d.shuffle(700).batch(700)\n",
        "with tf.device(\"/device:GPU:0\"):\n",
        "    history = model.fit(d,epochs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0YkShu1CH_V"
      },
      "outputs": [],
      "source": [
        "model.save('E:/q4/temp.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxnpr5OSCH_V"
      },
      "source": [
        "모델 검증  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BndX7Wq_CH_W"
      },
      "outputs": [],
      "source": [
        "loadedModel = tf.keras.models.load_model('E:/q4/temp.h5')\n",
        "vRootDir = 'E:/q4/유형별 두피 이미지/Validation/'\n",
        "\n",
        "vDirs = glob.glob(vRootDir+'**/*.json',recursive=True)\n",
        "imgs =[]\n",
        "labels = []\n",
        "length = len(vDirs)\n",
        "counter = 0\n",
        "'''\n",
        "for vDir in vDirs:\n",
        "    counter = counter +1\n",
        "    print(counter)\n",
        "    length = length -1\n",
        "    print(\"\\r남은수 : \",length,'counter : ',counter,end='')\n",
        "    with open(vDir,'r',encoding='UTF8') as file:\n",
        "            data = json.load(file)\n",
        "            #print(data)\n",
        "            #print(data['value_1']+data['value_2']+data['value_3']+data['value_4']+data['value_5']+data['value_6'])\n",
        "            encodedStatus = data['value_1']+data['value_2']+data['value_3']+data['value_4']+data['value_5']+data['value_6']\n",
        "            labels.append(decodeStatus(encodedStatus))\n",
        "        \n",
        "            imgDir = (vDir.replace('라벨','원천')).replace('json','jpg')\n",
        "            #print(imgDir)\n",
        "            imgData = np.array(Image.open(imgDir).resize((width,height)).convert('RGB'))\n",
        "            imgs.append(imgData)\n",
        "            file.close()\n",
        "imgs=np.array(imgs)\n",
        "imgs=imgs/255\n",
        "imgs=imgs.reshape(-1,width,height,3)\n",
        "'''\n",
        "def gen2():\n",
        "    for lDir in vDirs:\n",
        "        with open(lDir,'r',encoding='UTF8') as file:\n",
        "                data = json.load(file)\n",
        "                #print(data)\n",
        "                #print(data['value_1']+data['value_2']+data['value_3']+data['value_4']+data['value_5']+data['value_6'])\n",
        "                encodedStatus = data['value_1']+data['value_2']+data['value_3']+data['value_4']+data['value_5']+data['value_6']\n",
        "                \n",
        "        \n",
        "                imgDir = (lDir.replace('라벨','원천')).replace('json','jpg')\n",
        "                #print(imgDir)\n",
        "                imgData = np.array(Image.open(imgDir).resize((width,height)).convert('RGB'))\n",
        "                imgData = imgData/255 \n",
        "               \n",
        "            \n",
        "\n",
        "                label = decodeStatus(encodedStatus)\n",
        "                label=np.array(label)\n",
        "                label=keras.utils.to_categorical(label,9)\n",
        "                label=label.astype(np.int8)\n",
        "               \n",
        "\n",
        "                \n",
        "                yield(imgData,label)\n",
        "vdata = tf.data.Dataset.from_generator(gen2,(tf.int16,9),((width,height,3),(9)))\n",
        "vdata = vdata.batch(700)\n",
        "\n",
        "print('evaluate start')\n",
        "score = loadedModel.evaluate(vdata)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quuHt3zmCH_W",
        "outputId": "b185bcba-5742-42a0-b7cd-7eb1618f7aa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.4406474828720093"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evScore\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}